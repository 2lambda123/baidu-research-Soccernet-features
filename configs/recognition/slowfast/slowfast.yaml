MODEL: #MODEL field
  framework: "Recognizer3D"
  backbone:
    name: "ResNetSlowFast"
    res_depth: 50 # Not Optional, only 50 now.
    alpha: 4
    beta: 8
    width_per_group: 64
    fusion_kernel_sz: 7 #5?
  head:
    name: "SlowfastHead"
    width_per_group: 64
    alpha: 4
    beta: 8
    num_classes: 400
    num_frames: 32
    crop_size: 224  #independent to test or train mode
    dropout_rate: 0.5

DATASET: #DATASET field
  batch_size: 6 #single bacth size
  num_workers: 0 #8
  train:
    name: "SlowfastVideoDataset"
    file_path: "/workspace/huangjun12/PaddleProject/PaddleVideo/Experiment/PaddleVideo/data/k400/part-10cls/train.csv" #Mandatory, train data index file path
  valid:
    name: "SlowfastVideoDataset"
    file_path: "/workspace/huangjun12/PaddleProject/PaddleVideo/Experiment/PaddleVideo/data/k400/part-10cls/val.csv" #Mandatory, valid data index file path
    valid_mode: True
    num_ensemble_views: 3
    num_spatial_crops: 10

PIPELINE: #PIPELINE field
  train: #Mandotary, indicate the pipeline to deal with the training data, associate to the 'paddlevideo/loader/pipelines/'
    decode_sampler:
      name: "DecodeSampler"
      num_frames: 32
      sampling_rate: 2
      target_fps: 30
    transform: #Mandotary, image transfrom operator
      - SFScale:
          min_size: 256
          max_size: 320
      - SFCrop:
          target_size: 224
      - SFlip:
      - SFColorNorm:
          c_mean: [0.45, 0.45, 0.45]
          c_std: [0.225, 0.225, 0.225]
      - SFPackOutput:
          slowfast_alpha: 4


  valid: #Mandatory, indicate the pipeline to deal with the validing data. associate to the 'paddlevideo/loader/pipelines/'
    decode_sampler:
      name: "DecodeSampler"
      num_frames: 32
      sampling_rate: 2
      target_fps: 30
    transform: #Mandotary, image transfrom operator
      - SFScale:
          min_size: 224   #?
          max_size: 224  #?
      - SFCrop:
          target_size: 224  #256???
      - SFColorNorm:
          c_mean: [0.45, 0.45, 0.45]
          c_std: [0.225, 0.225, 0.225]
      - SFPackOutput:
          slowfast_alpha: 4

OPTIMIZER: #OPTIMIZER field
  name: 'Momentum'
  momentum: 0.9
  learning_rate:
    name: 'PiecewiseDecay'
    boundaries: None  # cal in lr.py
    values: None #cal in lr.py
    data_size: None #get from train.py
    max_epoch: 196
    warmup_epochs: 34
    warmup_start_lr: 0.01
    base_lr: 0.1
  weight_decay:
    name: 'L2'
    value: 1e-4
  use_nesterov: True

EVALUATION:
  interval: 1
  function: "topk"
  topk: (1,5)

log_interval: 1 #Optional, the interal of logger, default:10
epochs: 196 #Mandatory, total epoch  TODO delete??
log_level: "INFO"
resume_from: "" #checkpoint path.
