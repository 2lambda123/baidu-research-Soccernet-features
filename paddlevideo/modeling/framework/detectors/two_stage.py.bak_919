import paddle 
import paddle.nn as nn
from ... import builder
import paddle.distributed as dist

# from mmdet.core import bbox2result, bbox2roi, build_assigner, build_sampler
#from ..builder import DETECTORS, build_backbone, build_head, build_neck
from ...registry import DETECTORS
from .base import BaseDetector
chaj_print = 0
chaj_print_val = 0

def print_2_af_extract_feat_x_i(_str, _rank, _i, _x):
    if 1:
        f = open('af_extract_feat_x_'+str(_rank)+'_'+str(_i), 'w')
        print(_x,file=f)#,_file,_line)
        f.close()


@DETECTORS.register()
class TwoStageDetector(BaseDetector):
    """Base class for two-stage detectors.

    Two-stage detectors typically consisting of a region proposal network and a
    task-specific regression head.
    """

    def __init__(self,
                 backbone,
                 #bbox_roi_extractor,
                 neck=None,
                 rpn_head=None,
                 roi_head=None,
                 train_cfg=None,
                 test_cfg=None,
                 pretrained=None):
        super(TwoStageDetector, self).__init__()
        print("chajchaj, bf call build_backbone, backbone:",backbone)
        self.backbone = builder.build_backbone(backbone)
        print("chajchaj, af call build_backbone, self.backbone:",self.backbone)

        #print("chajchaj, bf call build_roi_extractor, bbox_roi_extractor:", bbox_roi_extractor)
        #self.bbox_roi_extractor = builder.build_roi_extractor(bbox_roi_extractor)
        #print("chajchaj, bf call build_roi_extractor, self.bbox_roi_extractor:",self.bbox_roi_extractor)

        if neck is not None:
            print("chajchaj, bf call build_neck, neck:",neck)
            self.neck = build_neck(neck)
            print("chajchaj, af call build_neck, neck:",neck)

        if rpn_head is not None:
            rpn_train_cfg = train_cfg.rpn if train_cfg is not None else None
            rpn_head_ = rpn_head.copy()
            rpn_head_.update(train_cfg=rpn_train_cfg, test_cfg=test_cfg.rpn)
            self.rpn_head = build_head(rpn_head_)

        if roi_head is not None:
            # update train and test cfg here for now
            # TODO: refactor assigner & sampler
            #print("chajchaj, bf call roi_head.update, roi_head:",roi_head)
            #print("chajchaj, bf call roi_head.update train_cfg:",train_cfg)
            #rcnn_train_cfg = train_cfg.rcnn if train_cfg is not None else None
            #roi_head.update(train_cfg=rcnn_train_cfg)
            #roi_head.update(test_cfg=test_cfg.rcnn)
            print("chajchaj, bf call build_head, roi_head:",roi_head)
            self.roi_head = builder.build_head(roi_head)
            print("chajchaj, bf call build_head, roi_head:",roi_head)

        self.train_cfg = train_cfg
        self.test_cfg = test_cfg

        if pretrained is not None:
            self.init_weights(pretrained=pretrained)

    @property
    def with_rpn(self):
        """bool: whether the detector has RPN"""
        return hasattr(self, 'rpn_head') and self.rpn_head is not None

    @property
    def with_roi_head(self):
        """bool: whether the detector has a RoI head"""
        return hasattr(self, 'roi_head') and self.roi_head is not None

    def init_weights(self, pretrained=None):
        """Initialize the weights in detector.

        Args:
            pretrained (str, optional): Path to pre-trained weights.
                Defaults to None.
        """
        print("chajchaj,TwoStageDetector,pretrained:",pretrained) 
        super(TwoStageDetector, self).init_weights(pretrained)
        self.backbone.init_weights(pretrained=pretrained)
        if self.with_neck:
            if isinstance(self.neck, nn.Sequential):
                for m in self.neck:
                    m.init_weights()
            else:
                self.neck.init_weights()
        if self.with_rpn:
            self.rpn_head.init_weights()
        if self.with_roi_head:
            self.roi_head.init_weights(pretrained)

    def extract_feat(self, img, iter_num, flag="train"):
        """Directly extract features from the backbone+neck."""
        x = self.backbone(img, iter_num,flag)
        if chaj_print:
            print("chajchaj, two_stage, af self.backbone, slow.shape:", x[0].shape, "fast.shape:", x[1].shape)
            print("chajchaj, two_stage, af self.backbone, x:", x)
        #if self.with_neck:
        #    x = self.neck(x)
        return x

    def forward_dummy(self, img):
        """Used for computing network flops.

        See `mmdetection/tools/analysis_tools/get_flops.py`
        """
        outs = ()
        # backbone
        x = self.extract_feat(img)
        # rpn
        if self.with_rpn:
            rpn_outs = self.rpn_head(x)
            outs = outs + (rpn_outs, )
        proposals = torch.randn(1000, 4).to(img.device)
        # roi_head
        roi_outs = self.roi_head.forward_dummy(x, proposals)
        outs = outs + (roi_outs, )
        return outs

    #def forward_train(self,
    def train_step(self, iter_num,
                      data, #img,
                      #img_metas,
                      #gt_bboxes,
                      #gt_labels,
                      #gt_bboxes_ignore=None,
                      #gt_masks=None,
                      #proposals=None,
                      **kwargs):
        """
        Args:
            img (Tensor): of shape (N, C, H, W) encoding input images.
                Typically these should be mean centered and std scaled.

            img_metas (list[dict]): list of image info dict where each dict
                has: 'img_shape', 'scale_factor', 'flip', and may also contain
                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.
                For details on the values of these keys see
                `mmdet/datasets/pipelines/formatting.py:Collect`.

            gt_bboxes (list[Tensor]): Ground truth bboxes for each image with
                shape (num_gts, 4) in [tl_x, tl_y, br_x, br_y] format.

            gt_labels (list[Tensor]): class indices corresponding to each box

            gt_bboxes_ignore (None | list[Tensor]): specify which bounding
                boxes can be ignored when computing the loss.

            gt_masks (None | Tensor) : true segmentation masks for each box
                used if the architecture supports a segmentation task.

            proposals : override rpn proposals with custom proposals. Use when
                `with_rpn` is False.

        Returns:
            dict[str, Tensor]: a dictionary of loss components
        """
        img_slow = data[0]
        img_fast = data[1]
        #proposals=data[2]
        #gt_bboxes=data[3]
        #gt_labels=data[4]
        #scores,entity_ids=data[5],data[6]
        #img_metas=scores,entity_ids
        #img_shape = data[7]
        #img_idx=data[8]
        ###list
        #proposals=data[2][0]
        #gt_bboxes=data[2][1]
        #gt_labels=data[2][2]
        #scores,entity_ids=data[2][3],data[2][4]
        #img_metas=scores,entity_ids
        #img_shape = data[2][5]
        #img_idx=data[2][6]
        pad_proposals=data[2]
        pad_gt_bboxes=data[3]
        pad_gt_labels=data[4]
        pad_scores,pad_entity_ids=data[5],data[6]
        len_proposals = data[9]
        len_gt_bboxes = data[10]
        len_gt_labels = data[11]
        len_scores = data[12]
        len_entity_ids = data[13]
        if chaj_print:
            print("chajchaj, TwoStageDetector forward_train start, len_proposals:",len_proposals)
            print("chajchaj, TwoStageDetector forward_train start, len_gt_bboxes:",len_gt_bboxes)
            print("chajchaj, TwoStageDetector forward_train start, len_gt_labels:",len_gt_labels)
            print("chajchaj, TwoStageDetector forward_train start, len_scores:",len_scores)
            print("chajchaj, TwoStageDetector forward_train start, len_entity_ids:",len_entity_ids)
            print("chajchaj, TwoStageDetector forward_train start, pad_proposals:",pad_proposals)
            print("chajchaj, TwoStageDetector forward_train start, pad_gt_bboxes:",pad_gt_bboxes)
            print("chajchaj, TwoStageDetector forward_train start, pad_gt_labels:",pad_gt_labels)
            print("chajchaj, TwoStageDetector forward_train start, pad_scores:",pad_scores)
            print("chajchaj, TwoStageDetector forward_train start, pad_entity_ids:",pad_entity_ids)
        N = pad_proposals.shape[0]
        if chaj_print:
            print("chajchaj, TwoStageDetector forward_train start, N:",N)
        proposals = []
        gt_bboxes = []
        gt_labels = []
        scores = []
        entity_ids = []
        for bi in range(N):
            pad_proposal = pad_proposals[bi]
            if chaj_print:
                print("chajchaj, TwoStageDetector forward_train start, bi:",bi, "pad_proposal:",pad_proposal)
            len_proposal = len_proposals[bi]
            index_proposal = paddle.arange(len_proposal)
            if chaj_print:
                print("chajchaj, TwoStageDetector forward_train start, bi:",bi, "index_proposal:",index_proposal)
            proposal = paddle.index_select(x=pad_proposal, index=index_proposal, axis=0)
            if chaj_print:
                print("chajchaj, TwoStageDetector forward_train start, bi:",bi, "proposal:",proposal)
            proposals.append(proposal)

            pad_gt_bbox = pad_gt_bboxes[bi]
            len_gt_bbox = len_gt_bboxes[bi]
            index_gt_bbox = paddle.arange(len_gt_bbox)
            gt_bbox = paddle.index_select(x=pad_gt_bbox, index=index_gt_bbox, axis=0)
            gt_bboxes.append(gt_bbox)

            pad_gt_label = pad_gt_labels[bi]
            len_gt_label = len_gt_labels[bi]
            index_gt_label = paddle.arange(len_gt_label)
            gt_label = paddle.index_select(x=pad_gt_label, index=index_gt_label, axis=0)
            gt_labels.append(gt_label)

            pad_score = pad_scores[bi]
            len_score = len_scores[bi]
            index_score = paddle.arange(len_score)
            score = paddle.index_select(x=pad_score, index=index_score, axis=0)
            scores.append(score)

            pad_entity_id = pad_entity_ids[bi]
            len_entity_id = len_entity_ids[bi]
            index_entity_id = paddle.arange(len_entity_id)
            entity_id = paddle.index_select(x=pad_entity_id, index=index_entity_id, axis=0)
            entity_ids.append(entity_id)
 
        if chaj_print:
            print("chajchaj, TwoStageDetector forward_train start, proposals:",proposals)
            print("chajchaj, TwoStageDetector forward_train start, gt_bboxes:",gt_bboxes)
            print("chajchaj, TwoStageDetector forward_train start, gt_labels:",gt_labels)
            print("chajchaj, TwoStageDetector forward_train start, scores:",scores)
            print("chajchaj, TwoStageDetector forward_train start, entity_ids:",entity_ids)
 
        img_shape = data[7]
        img_idx=data[8]
        img_metas=scores,entity_ids
 
        #gt_bboxes_ignore=None,
        #gt_masks=None,

        if chaj_print:
            print("chajchaj, TwoStageDetector forward_train start, img_idx:",img_idx, "img_slow:",img_slow)
            print("chajchaj, TwoStageDetector forward_train start, img_idx:",img_idx, "img_fast:",img_fast)
            print("chajchaj, TwoStageDetector forward_train start, img_idx:",img_idx, "img_metas:",img_metas) 
            print("chajchaj, TwoStageDetector forward_train start, img_idx:",img_idx, "gt_bboxes:", gt_bboxes) 
            print("chajchaj, TwoStageDetector forward_train start, img_idx:",img_idx, "gt_labels:",gt_labels) 
            #print("chajchaj, TwoStageDetector forward_train start, gt_bboxes_ignore:",gt_bboxes_ignore) 
            #print("chajchaj, TwoStageDetector forward_train start, gt_masks:",gt_masks) 
            print("chajchaj, TwoStageDetector forward_train start, img_idx:",img_idx,"proposals:",proposals) 
        x = self.extract_feat(img=[img_slow,img_fast],iter_num=iter_num)
        #chajchaj, TwoStageDetector forward_train extract_feat img.shape: torch.Size([3, 32, 256, 256]) x.shape: torch.Size([2, 2048, 8, 16, 16])
        #print("chajchaj, TwoStageDetector forward_train extract_feat img.shape:", img[0].shape, "x.shape:", x[0].shape)
        #print("chajchaj, TwoStageDetector forward_train extract_feat x:", x)

        losses = dict()

        # RPN forward and loss
        #False
        if chaj_print:
            print("chajchaj, TwoStageDetector self.with_rpn:",self.with_rpn)
        if self.with_rpn:
            proposal_cfg = self.train_cfg.get('rpn_proposal',
                                              self.test_cfg.rpn)
            rpn_losses, proposal_list = self.rpn_head.forward_train(
                x,
                img_metas,
                gt_bboxes,
                gt_labels=None,
                gt_bboxes_ignore=gt_bboxes_ignore,
                proposal_cfg=proposal_cfg)
            losses.update(rpn_losses)
        else:
            proposal_list = proposals

        if chaj_print:
            print("chajchaj, TwoStageDetector self.roi_head:",self.roi_head) 
        roi_losses = self.roi_head.train_step(iter_num, x, img_metas, proposal_list,
                                                 gt_bboxes, gt_labels,
                                                 #gt_bboxes_ignore, gt_masks,
                                                 **kwargs)
        losses.update(roi_losses)
        #if chaj_print:
        print("chajchaj, TwoStageDetector forward_train end, roi_losses:",roi_losses) 

        return losses

    async def async_simple_test(self,
                                img,
                                img_meta,
                                proposals=None,
                                rescale=False):
        """Async test without augmentation."""
        assert self.with_bbox, 'Bbox head must be implemented.'
        x = self.extract_feat(img)

        if proposals is None:
            proposal_list = await self.rpn_head.async_simple_test_rpn(
                x, img_meta)
        else:
            proposal_list = proposals

        return await self.roi_head.async_simple_test(
            x, proposal_list, img_meta, rescale=rescale)

    #def simple_test(self, img, img_metas, proposals=None, rescale=False):
    def val_step(self, iter_num, data, #img_metas, proposals=None, 
                rescale=False):
        """Test without augmentation."""
        #assert self.with_bbox, 'Bbox head must be implemented.'

        #x = self.extract_feat(img)

        ## get origin input shape to onnx dynamic input shape
        #if torch.onnx.is_in_onnx_export():
        #    img_shape = torch._shape_as_tensor(img)[2:]
        #    img_metas[0]['img_shape_for_onnx'] = img_shape

        img_slow = data[0]
        img_fast = data[1]
        #proposals=data[2]
        #gt_bboxes=data[3]
        #gt_labels=data[4]
        #scores,entity_ids=data[5],data[6]

        ##TODO: same with train_step.  need to merge. start
        pad_proposals=data[2]
        pad_gt_bboxes=data[3]
        pad_gt_labels=data[4]
        pad_scores,pad_entity_ids=data[5],data[6]
        len_proposals = data[9]
        len_gt_bboxes = data[10]
        len_gt_labels = data[11]
        len_scores = data[12]
        len_entity_ids = data[13]
        if chaj_print_val:
            print("chajchaj, TwoStageDetector forward_train start, len_proposals:",len_proposals)
            print("chajchaj, TwoStageDetector forward_train start, len_gt_bboxes:",len_gt_bboxes)
            print("chajchaj, TwoStageDetector forward_train start, len_gt_labels:",len_gt_labels)
            print("chajchaj, TwoStageDetector forward_train start, len_scores:",len_scores)
            print("chajchaj, TwoStageDetector forward_train start, len_entity_ids:",len_entity_ids)
            print("chajchaj, TwoStageDetector forward_train start, pad_proposals:",pad_proposals)
            print("chajchaj, TwoStageDetector forward_train start, pad_gt_bboxes:",pad_gt_bboxes)
            print("chajchaj, TwoStageDetector forward_train start, pad_gt_labels:",pad_gt_labels)
            print("chajchaj, TwoStageDetector forward_train start, pad_scores:",pad_scores)
            print("chajchaj, TwoStageDetector forward_train start, pad_entity_ids:",pad_entity_ids)
        N = pad_proposals.shape[0]
        if chaj_print_val:
            print("chajchaj, TwoStageDetector forward_train start, N:",N)
        proposals = []
        gt_bboxes = []
        gt_labels = []
        scores = []
        entity_ids = []
        for bi in range(N):
            pad_proposal = pad_proposals[bi]
            if chaj_print_val:
                print("chajchaj, TwoStageDetector forward_train start, bi:",bi, "pad_proposal:",pad_proposal)
            len_proposal = len_proposals[bi]
            index_proposal = paddle.arange(len_proposal)
            if chaj_print_val:
                print("chajchaj, TwoStageDetector forward_train start, bi:",bi, "index_proposal:",index_proposal)
            proposal = paddle.index_select(x=pad_proposal, index=index_proposal, axis=0)
            if chaj_print_val:
                print("chajchaj, TwoStageDetector forward_train start, bi:",bi, "proposal:",proposal)
            proposals.append(proposal)

            pad_gt_bbox = pad_gt_bboxes[bi]
            len_gt_bbox = len_gt_bboxes[bi]
            index_gt_bbox = paddle.arange(len_gt_bbox)
            gt_bbox = paddle.index_select(x=pad_gt_bbox, index=index_gt_bbox, axis=0)
            gt_bboxes.append(gt_bbox)

            pad_gt_label = pad_gt_labels[bi]
            len_gt_label = len_gt_labels[bi]
            index_gt_label = paddle.arange(len_gt_label)
            gt_label = paddle.index_select(x=pad_gt_label, index=index_gt_label, axis=0)
            gt_labels.append(gt_label)

            pad_score = pad_scores[bi]
            len_score = len_scores[bi]
            index_score = paddle.arange(len_score)
            score = paddle.index_select(x=pad_score, index=index_score, axis=0)
            scores.append(score)

            pad_entity_id = pad_entity_ids[bi]
            len_entity_id = len_entity_ids[bi]
            index_entity_id = paddle.arange(len_entity_id)
            entity_id = paddle.index_select(x=pad_entity_id, index=index_entity_id, axis=0)
            entity_ids.append(entity_id)
 
        if chaj_print_val:
            print("chajchaj, TwoStageDetector val_step start, proposals:",proposals)
            print("chajchaj, TwoStageDetector val_step start, gt_bboxes:",gt_bboxes)
            print("chajchaj, TwoStageDetector val_step start, gt_labels:",gt_labels)
            print("chajchaj, TwoStageDetector val_step start, scores:",scores)
            print("chajchaj, TwoStageDetector val_step start, entity_ids:",entity_ids)
        ##TODO: same with train_step.  need to merge. end
 
        img_shape = data[7]
        img_metas=scores,entity_ids
        if chaj_print_val:
            print("chajchaj, TwoStageDetector val_step start, np_img_slow:",img_slow.numpy())
            print("chajchaj, TwoStageDetector val_step start, np_img_fast:",img_fast.numpy())
            print("chajchaj, TwoStageDetector val_step start, type(img_metas):",type(img_metas)) 
            print("chajchaj, TwoStageDetector val_step start, img_metas:",img_metas) 
            #print("chajchaj, TwoStageDetector val_step start, gt_bboxes:", gt_bboxes) 
            #print("chajchaj, TwoStageDetector val_step start, gt_labels:",gt_labels) 
            #print("chajchaj, TwoStageDetector val_step start, type(proposals):",type(proposals)) 
            #print("chajchaj, TwoStageDetector val_step start, proposals:",proposals) 
            print("chajchaj, TwoStageDetector val_step start, img_shape:",img_shape) 
        x = self.extract_feat(img=[img_slow,img_fast],iter_num=iter_num,flag="val") #TODO: align with mm
        if chaj_print_val:
            #print("chajchaj, TwoStageDetector val_step extract_feat img.shape:", img[0].shape, "x.shape:", x[0].shape)
            print("chajchaj, TwoStageDetector val_step extract_feat x:", x)
        if chaj_print_val:
            rank = dist.get_rank()
            print_2_af_extract_feat_x_i("chajchaj_pv_two_stage.py, val_step, af extract_feat, x:",rank, iter_num, x)

        #print("chajchaj, TwoStageDetector val_step proposals:",proposals) 
        if proposals is None:
            proposal_list = self.rpn_head.simple_test_rpn(x, img_metas)
        else:
            proposal_list = proposals

        #chajchaj, TwoStageDetector val_step self.roi_head: AVARoIHead(
        #  (bbox_roi_extractor): SingleRoIExtractor3D()
        #  (bbox_head): BBoxHeadAVA(
        #    (temporal_pool): AdaptiveAvgPool3D(output_size=(1, None, None))
        #    (spatial_pool): AdaptiveMaxPool3D(output_size=(None, 1, 1), return_mask=False)
        #    (dropout): Dropout(p=0.5, axis=None, mode=upscale_in_train)
        #    (fc_cls): Linear(in_features=2304, out_features=81, dtype=float32)
        #  )
        #)
        if chaj_print_val:
            print("chajchaj, TwoStageDetector val_step self.roi_head:",self.roi_head) 
        return self.roi_head.simple_test(iter_num,           #TODO: dev and align with mm
            x, proposal_list[0], img_metas[0], img_shape, rescale=rescale)
 


    def aug_test(self, imgs, img_metas, rescale=False):
        """Test with augmentations.

        If rescale is False, then returned bboxes and masks will fit the scale
        of imgs[0].
        """
        x = self.extract_feats(imgs)
        proposal_list = self.rpn_head.aug_test_rpn(x, img_metas)
        return self.roi_head.aug_test(
            x, proposal_list, img_metas, rescale=rescale)
