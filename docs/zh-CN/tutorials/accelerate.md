简体中文 | [English](../../en/tutorials/accelerate.md)

- [简介](#简介)
- [更优的解码库Decord](#更优的解码库Decord)
- [多进程加速Dataloader](#多进程加速Dataloader)
- [数据预处理DALI](#数据预处理DALI)
- [预先解码存成图像](#预先解码存成图像)
- [Multigrid加速策略算法](#Multigrid加速策略算法)
- [分布式训练](#分布式训练)


# 简介

视频任务相比于图像任务的训练往往更加耗时，其原因主要有两点:
- 数据：视频解码耗时。mp4/mkv等视频文件都是经过encode后的压缩文件，通过需要经过解码和抽帧步骤才能得到原始的图像数据流，之后经过图像变换/增强操作才能将其喂入网络进行训练。如果视频帧数多，解码过程是极其耗时的。
- 模型：视频任务使用的模型通常有更大的参数量与计算量。为学习时序特征，视频模型一般会使用3D卷积核/(2+1)D/双流网络，这都会使得模型的参数量与计算量大大增加。

为了加速视频模型的训练，可以分别从模型角度和数据角度考虑。模型上可以通过op融合或混合精度训练的方式提升op运算效率。针对[TSM模型]()，我们实现了[temporal shift op]()，在节省显存的同时加速训练过程。而对于单机训练，视频模型的训练瓶颈大多是在数据预处理上，因此本教程主要介绍在数据处理上的一些加速经验，同时这些能力都已经集成进PaddleVideo中，欢迎试用~

# 更优的解码库Decord

视频在喂入网络之前，需要经过一系列的数据预处理操作得到数据流，这些操作通常包括:

- 解码: 将视频文件解码成数据流
- 抽帧: 从视频中抽取部分帧用于网络训练
- 数据增强：缩放、裁剪、随机反转、正则化

其中解码是最为耗时的。相较于传统的opencv或pyAV解码库，这里推荐使用性能更优的解码库[decord]()，其官方给出的性能数据如下图:

目前[SlowFast]()模型使用decord进行视频解码([源码]())，对单进程的速度提升有较大作用。

本地实测数据如下:
环境 版本
paddle原实现 (cv2解码):  0.2096503508090973
pytorch实现(pyav实现):   0.1926709806919098
Paddle的decord实现:  0.13788146734237672

# 多进程加速Dataloader

数据准备好后喂入网络进行训练，网络运算使用GPU并行加速，其运算速度是很快的。因此对于单个进程来说，速度瓶颈大多在数据处理部分，GPU大部分时间是在等待CPU完成数据预处理。
飞桨2.0使用[Dataloader]()进行数据加载，DataLoader支持单进程和多进程的数据加载方式，当 num_workers 大于0时，将使用多进程方式异步加载数据。多进程加速协作，可以overlap掉GPU大部分等待的时间，提升GPU利用率，显著加速训练过程。

性能数据对比如下:
num_workers=0 
num_workers=4

结合使用decord和飞桨dataloader，加上在数据增强部分做一些细节优化，SlowFast模型训练速度增益为100%，详细数据可以参考[benchmark]()。

# 数据预处理DALI

既然GPU等待CPU进行数据处理耗时，能否把数据处理放到GPU上呢？[NVIDIA DALI]()将数据预处理pipeline转移到GPU上执行，可以显著提升训练速度。针对视频文件，DALI提供`VideoReader`op进行解码抽帧操作，但目前其仅支持连续采样的方式进行抽帧。而视频领域常用的2D模型TSN或TSM，它们均采用分段采样方式，即把视频均匀分成N段segument，然后在每个segument内随机选取一帧，最后把选取的帧组合作为输入张量。为此，我们基于DALI进行了二次开发，实现了支持分段采样方式的`VideoReader`op。为方便用户使用，我们提供了配置好的docker运行环境，具体使用方法参考[TSN-DALI使用教程]()。

# 预先解码存成图像

这是一种简单直接的方法，既然视频解码耗时，那可以事先将视频解码好，存成图片，模型训练时直接读取图像即可。这种方法可以显著提升视频模型训练速度，在XXX上大约提速3倍。但它也有一个很明显的缺点，就是需要耗费大量的内存空间，以kinetics-400数据集为例，共包含24万个训练样本，mp4文件约130多G，解码存成图像后，占用的内存空间约为[]T，所以这种方法比较适用于较小规模的数据集，如ucf-101。PaddleVideo提供了[预先解码]()的脚本，并且TSN和TSM模型均直接使用frame格式的数据进行训练，详细参考[TSN]() [TSM]()。

# Multigrid加速策略算法


# 分布式训练 
